{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "cDQDF0EHT0Ee",
    "outputId": "e477e448-59d1-41e8-ca2b-bd4e68d5e951"
   },
   "outputs": [],
   "source": [
    "\"\"\" Define constants and configs \"\"\"\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Using GPU:', bool(tf.test.gpu_device_name()))\n",
    "\n",
    "\n",
    "USE_GOOGLE_DRIVE = False\n",
    "# BASE_DIR = Path(\"/content/drive/My Drive/datasett\")\n",
    "BASE_DIR = Path(\".\")\n",
    "IMAGE_DIR = {\n",
    "    'train': BASE_DIR / 'organized/training',\n",
    "    'validation': BASE_DIR / 'organized/validation',\n",
    "    'test': BASE_DIR / 'organized/test'\n",
    "}\n",
    "\n",
    "if USE_GOOGLE_DRIVE:\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Connect to google drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Go to https://drive.google.com/drive/folders/1-75Md9VucbQsmcb52JYk3wOlv8wqW_sl\n",
    "    # and add it to your drive\n",
    "\n",
    "# Print files per folder\n",
    "!find './organized' -mindepth 2 -type d  -exec du --inodes {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a emotion classifier from MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "bTdiXQRFenqk",
    "outputId": "0d94f1b3-8076-472c-d43c-7c5d063a0915"
   },
   "outputs": [],
   "source": [
    "\"\"\" Load images with real-time data augmentation \"\"\"\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenetv2 import preprocess_input\n",
    "\n",
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE=20\n",
    "\n",
    "# Prepare to load the images\n",
    "datagen_attrs = dict(\n",
    "    batch_size=BATCH_SIZE,  # How many images will be used in each step\n",
    "    target_size=IMAGE_SHAPE[:2],  # Resize to fit models' input\n",
    "    class_mode='categorical'  # Return labels as 2D one-hot array\n",
    ")\n",
    "\n",
    "datagen = lambda: ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "print('Setting up train data:', end=' ')\n",
    "train_it = datagen().flow_from_directory(IMAGE_DIR['train'], **datagen_attrs)\n",
    "print('Setting up validation data:', end=' ')\n",
    "val_it = datagen().flow_from_directory(IMAGE_DIR['validation'], **datagen_attrs)\n",
    "# print('Setting up test data:', end=' ')\n",
    "# test_it = datagen().flow_from_directory(IMAGE_DIR['test'], **datagen_attrs)\n",
    "\n",
    "num_classes=len(train_it.class_indices)\n",
    "\n",
    "# Print classes summary\n",
    "print('Loaded', num_classes, 'classes:', train_it.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asrnpMHOpypC"
   },
   "outputs": [],
   "source": [
    "\"\"\" Prepare the custom MobileNetV2 (emotion predictor) model \"\"\"\n",
    "\n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "FEATURE_EXTRACTOR_POLLING = 'avg'\n",
    "ACTIVATION_FUNC = 'softmax'\n",
    "\n",
    "# Create a MobileNetV2\n",
    "mnv2_feature_extractor = MobileNetV2(\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    include_top=False,  # Don't include the last layer (1000 classes classification)\n",
    "    weights='imagenet',  # Use imagenet pre trained weights\n",
    "    pooling=FEATURE_EXTRACTOR_POLLING  #  Reduce the size of the feature array\n",
    ")\n",
    "\n",
    "# Create an output layer and bind it to the feature extractor MobileNetV2\n",
    "custom_output = Dense(num_classes, activation=ACTIVATION_FUNC, name='predictions')(mnv2_feature_extractor.output)\n",
    "mnv2_emotion_predictor = Model(inputs=mnv2_feature_extractor.input, outputs=custom_output)\n",
    "\n",
    "# Print model architecture\n",
    "mnv2_emotion_predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sLOH5iIy-Py5",
    "outputId": "b7a4bb75-df95-438c-ca75-ea74d2c4cdc6"
   },
   "outputs": [],
   "source": [
    "\"\"\" Train the custom model \"\"\"\n",
    "import time\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "# Train config\n",
    "LOSS = 'mean_squared_error'\n",
    "OPTIMIZER = Adadelta(lr=0.5, rho=0.95, epsilon=1e-6)\n",
    "EPOCHS = 400\n",
    "\n",
    "# Use ModelCheckpoint to save the training progress\n",
    "filepath = str(BASE_DIR / \"weights/weights-improvement-224x224-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# Use TensorBoard to plot progress\n",
    "tensorboard = TensorBoard(log_dir=str(BASE_DIR / \"board/{}\".format(time.time())), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Train\n",
    "mnv2_emotion_predictor.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "try:\n",
    "    mnv2_emotion_predictor.fit_generator(\n",
    "        train_it,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=BATCH_SIZE//2,  #  sample_size = batch_size * steps_per_epochs\n",
    "        validation_data=val_it,\n",
    "        validation_steps=BATCH_SIZE//4,\n",
    "        callbacks=[checkpoint, tensorboard])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted via keyboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model as a feature extractor for a SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load images with real-time data augmentation \"\"\"\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenetv2 import preprocess_input\n",
    "\n",
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE=100\n",
    "\n",
    "# Prepare to load the images\n",
    "datagen_attrs = dict(\n",
    "    batch_size=BATCH_SIZE,  # How many images will be used in each step\n",
    "    target_size=IMAGE_SHAPE[:2],  # Resize to fit models' input\n",
    "    class_mode='sparse'  # Return labels as 1D integer label array\n",
    ")\n",
    "\n",
    "datagen = lambda: ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "print('Setting up train data:', end=' ')\n",
    "train_it = datagen().flow_from_directory(IMAGE_DIR['train'], **datagen_attrs)\n",
    "print('Setting up validation data:', end=' ')\n",
    "val_it = datagen().flow_from_directory(IMAGE_DIR['validation'], **datagen_attrs)\n",
    "# print('Setting up test data:', end=' ')\n",
    "# test_it = datagen().flow_from_directory(IMAGE_DIR['test'], **datagen_attrs)\n",
    "\n",
    "num_classes=len(train_it.class_indices)\n",
    "\n",
    "# Print classes summary\n",
    "print('Loaded', num_classes, 'classes:', train_it.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvE7fnn5aCDw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "def load_model_from_file(model_path):\n",
    "    keras_backend = K.backend()\n",
    "    assert keras_backend == \"tensorflow\", \\\n",
    "        \"Only tensorflow-backed Keras models are supported, tried to load Keras model \" \\\n",
    "        \"with backend %s.\" % (keras_backend)\n",
    "    return load_model(model_path)\n",
    "\n",
    "def get_model_input_shape(model):\n",
    "    \"\"\" Returns the models first layer input shape as a tuple \"\"\"\n",
    "    return tuple(model.layers[0].input.shape.as_list())\n",
    "\n",
    "def get_feature_vector(data, model, learning_phase=0):\n",
    "    \"\"\" Returns the second-to-last layer output from a pretrained model\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    data: ndarray. Data to input into the model, must match its shape.\n",
    "    model: keras.engine.training.Model. Pretrained model\n",
    "    learning_phase: int. If the model has a different behavior in\n",
    "        training/testing phase, a suitable `learning_phase` must be \n",
    "        set: 0=TEST (default), 1=TRAIN.\n",
    "    Return\n",
    "    ------\n",
    "    ndarray. The feature array for all the images.\n",
    "    \"\"\"\n",
    "\n",
    "    get_layer_output = K.function(\n",
    "        [model.layers[0].input, K.learning_phase()], \n",
    "        [model.layers[-2].output])\n",
    "      \n",
    "    return get_layer_output([data, learning_phase])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnv2_classify_emotions  = load_model_from_file('weights-improvement-128x128-226-0.73.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Find min-max values for features over the whole train dataset \"\"\"\n",
    "import math\n",
    "\n",
    "max_array = np.zeros(1280)\n",
    "min_array = np.full(1280, fill_value=math.inf)\n",
    "\n",
    "for i, batch in enumerate(train_it, start=1):\n",
    "    X = batch[0]\n",
    "    print(i*BATCH_SIZE, end='\\r')\n",
    "    \n",
    "    features = get_feature_vector(X, mnv2_classify_emotions)\n",
    "    features = np.array(features)\n",
    "    max_array = np.maximum(max_array, np.amax(features, axis=0))\n",
    "    min_array = np.minimum(min_array, np.amin(features, axis=0))\n",
    "    \n",
    "    if i * BATCH_SIZE > train_it.samples:\n",
    "        break\n",
    "        \n",
    "max_array.tofile('max')\n",
    "min_array.tofile('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save the normalized features \"\"\"\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load features min/max arrays\n",
    "max_array = np.fromfile('max.ndarray')\n",
    "min_array = np.fromfile('min.ndarray')\n",
    "\n",
    "# Feature Normalization \n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit([min_array, max_array])\n",
    "\n",
    "# Save each batch in a file\n",
    "for i, batch in enumerate(train_it):\n",
    "    X, Y = batch\n",
    "    features = get_feature_vector(X, mnv2_classify_emotions)\n",
    "    features = min_max_scaler.transform(features)\n",
    "    np.array(features).tofile(f'{i:05d}-features.ndarray')\n",
    "    np.array(Y).tofile(f'{i:05d}-labels.ndarray')\n",
    "\n",
    "    if i * BATCH_SIZE > train_it.samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "max_array = np.fromfile('max.ndarray')\n",
    "min_array = np.fromfile('min.ndarray')\n",
    "\n",
    "# Feature Normalization \n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit([min_array, max_array])\n",
    "\n",
    "def go(model, clf, classes, max_iter=1000, tol=1e-5, epochs=300, steps_per_epoch=BATCH_SIZE//2,\n",
    "       validation_steps=BATCH_SIZE//4):\n",
    "\n",
    "    scores = {}\n",
    "    val_scores = {}\n",
    "\n",
    "    last_iter_score = 0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        scores[epoch] = {}\n",
    "        # For each batch\n",
    "        for epoch_step in range(1, steps_per_epoch + 1):\n",
    "            # Get normalized features from the images\n",
    "            X, Y = next(train_it)\n",
    "            features = get_feature_vector(X, model)\n",
    "            features = min_max_scaler.transform(features)\n",
    "\n",
    "            # Iter in this batch until max_iter or enhancement < tol\n",
    "            for i in range(max_iter):\n",
    "                clf.partial_fit(features, Y, classes=classes)\n",
    "                iter_score = clf.score(features, Y)\n",
    "\n",
    "                # Check iter enhancement\n",
    "                if iter_score - last_iter_score < tol:\n",
    "                    break\n",
    "\n",
    "                last_iter_score = iter_score\n",
    "\n",
    "            print(f'Epoch {epoch:4d} ({epoch_step:2d}/{steps_per_epoch}) - score: {iter_score:.5f}', end='\\r')\n",
    "            scores[epoch][epoch_step] = iter_score\n",
    "\n",
    "        # Reprint the last epoch step \n",
    "        print(f'Epoch {epoch:4d} ({steps_per_epoch}/{steps_per_epoch}) - score: {iter_score:.5f}', end='')\n",
    "\n",
    "        # Run some validation steps to compute the score\n",
    "        epoch_val_scores = []\n",
    "        for val_step in range(validation_steps):\n",
    "            X, Y = next(val_it)\n",
    "            features = get_feature_vector(X, model)  \n",
    "            features = min_max_scaler.transform(features)\n",
    "            val_score = clf.score(features, Y)\n",
    "            \n",
    "            epoch_val_scores.append(val_score)\n",
    "\n",
    "        val_scores[epoch] = np.average(epoch_val_scores)\n",
    "        print(f' - val_score: {val_scores[epoch]}')\n",
    "        \n",
    "        # save the classifier\n",
    "        with open(f'sgd-epoch-{epoch:03d}-(valscore-{val_scores[epoch]:.3f}).pkl', 'wb') as fid:\n",
    "            pickle.dump(clf, fid)    \n",
    "\n",
    "        yield\n",
    "\n",
    "# load it again\n",
    "# with open('sgd-epoch-30-valscore-0.5.pkl', 'rb') as fid:\n",
    "#     clf_loaded = pickle.load(fid)\n",
    "    \n",
    "clf = SGDClassifier(\n",
    "    penalty='l2',\n",
    "    loss='hinge',\n",
    "    random_state=0,\n",
    "    tol=1e-3,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "for _ in go(mnv2_classify_emotions, clf, classes=np.arange(7)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEPT9xNpb8cg"
   },
   "outputs": [],
   "source": [
    "\"\"\" Utils \"\"\"\n",
    "\n",
    "def extract_zip(zip_path, output_path):\n",
    "    \"\"\" Extract zip to a folder \"\"\"\n",
    "    import zipfile\n",
    "    zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
    "    zip_ref.extractall(output_path)\n",
    "    zip_ref.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classify_emotion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
